{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G2RQRgcfmdes"
   },
   "source": [
    "# Лабораторная работа 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6RXrbBbNmdev"
   },
   "source": [
    "Tensorflow 2.x\n",
    "\n",
    "1) Подготовка данных\n",
    "\n",
    "2) Использование Keras Model API\n",
    "\n",
    "3) Использование Keras Sequential + Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gUPFB3ZKmdew"
   },
   "source": [
    "https://www.tensorflow.org/tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-KLJDFXmdew"
   },
   "source": [
    "Для выполнения лабораторной работы необходимо установить tensorflow версии 2.0 или выше .\n",
    "\n",
    "Рекомендуется использовать возможности Colab'а по обучению моделей на GPU.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T10:32:01.394648Z",
     "start_time": "2024-03-21T10:32:01.378584Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1TSC3kHzmdex",
    "outputId": "578f857b-cd13-40b4-fd67-6becc266d599"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "USE_GPU = True\n",
    "\n",
    "if USE_GPU:\n",
    "    device = '/device:GPU:0'\n",
    "else:\n",
    "    device = '/cpu:0'\n",
    "\n",
    "# Constant to control how often we print when training models.\n",
    "print_every = 100\n",
    "print('Using device: ', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QW9-fCBumdey"
   },
   "source": [
    "# Подготовка данных\n",
    "Загрузите набор данных из предыдущей лабораторной работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T10:32:03.359832Z",
     "start_time": "2024-03-21T10:32:01.709774Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mLLN4mzDmdez",
    "outputId": "03032cc7-cfb9-49a1-858e-483c07991c7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 28, 28, 1)\n",
      "Train labels shape:  (49000,) int32\n",
      "Validation data shape:  (1000, 28, 28, 1)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (10000, 28, 28, 1)\n",
      "Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "def load_mnist(num_training=49000, num_validation=1000, num_test=10000):\n",
    "    \"\"\"\n",
    "    Fetch the CIFAR-10 dataset from the web and perform preprocessing to prepare\n",
    "    it for the two-layer neural net classifier. These are the same steps as\n",
    "    we used for the SVM, but condensed to a single function.\n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 dataset and use appropriate data types and shapes\n",
    "    mnist = tf.keras.datasets.mnist.load_data()\n",
    "    (X_train, y_train), (X_test, y_test) = mnist\n",
    "    X_train = np.asarray(X_train, dtype=np.float32)\n",
    "    y_train = np.asarray(y_train, dtype=np.int32).flatten()\n",
    "    X_test = np.asarray(X_test, dtype=np.float32)\n",
    "    y_test = np.asarray(y_test, dtype=np.int32).flatten()\n",
    "\n",
    "    # Subsample the data\n",
    "    mask = range(num_training, num_training + num_validation)\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = range(num_training)\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = range(num_test)\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "\n",
    "    # Normalize the data: subtract the mean pixel and divide by std\n",
    "    mean_pixel = X_train.mean(axis=(0, 1, 2), keepdims=True)\n",
    "    std_pixel = X_train.std(axis=(0, 1, 2), keepdims=True)\n",
    "    X_train = (X_train - mean_pixel) / std_pixel\n",
    "    X_val = (X_val - mean_pixel) / std_pixel\n",
    "    X_test = (X_test - mean_pixel) / std_pixel\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "# If there are errors with SSL downloading involving self-signed certificates,\n",
    "# it may be that your Python version was recently installed on the current machine.\n",
    "# See: https://github.com/tensorflow/tensorflow/issues/10779\n",
    "# To fix, run the command: /Applications/Python\\ 3.7/Install\\ Certificates.command\n",
    "#   ...replacing paths as necessary.\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "NHW = (0, 1, 2)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_mnist()\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_val = X_val.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape, y_train.dtype)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T10:32:03.390892Z",
     "start_time": "2024-03-21T10:32:03.361829Z"
    },
    "id": "zFdFh2Tsmdez"
   },
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, X, y, batch_size, shuffle=False):\n",
    "        \"\"\"\n",
    "        Construct a Dataset object to iterate over data X and labels y\n",
    "\n",
    "        Inputs:\n",
    "        - X: Numpy array of data, of any shape\n",
    "        - y: Numpy array of labels, of any shape but with y.shape[0] == X.shape[0]\n",
    "        - batch_size: Integer giving number of elements per minibatch\n",
    "        - shuffle: (optional) Boolean, whether to shuffle the data on each epoch\n",
    "        \"\"\"\n",
    "        assert X.shape[0] == y.shape[0], 'Got different numbers of data and labels'\n",
    "        self.X, self.y = X, y\n",
    "        self.batch_size, self.shuffle = batch_size, shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        N, B = self.X.shape[0], self.batch_size\n",
    "        idxs = np.arange(N)\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(idxs)\n",
    "        return iter((self.X[i:i+B], self.y[i:i+B]) for i in range(0, N, B))\n",
    "\n",
    "\n",
    "train_dset = Dataset(X_train, y_train, batch_size=64, shuffle=True)\n",
    "val_dset = Dataset(X_val, y_val, batch_size=64, shuffle=False)\n",
    "test_dset = Dataset(X_test, y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T10:32:03.438893Z",
     "start_time": "2024-03-21T10:32:03.392899Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WxhBcG5Jmde0",
    "outputId": "ada0f915-0842-48ae-ebc0-ed17a52b26d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (64, 28, 28, 1) (64,)\n",
      "1 (64, 28, 28, 1) (64,)\n",
      "2 (64, 28, 28, 1) (64,)\n",
      "3 (64, 28, 28, 1) (64,)\n",
      "4 (64, 28, 28, 1) (64,)\n",
      "5 (64, 28, 28, 1) (64,)\n",
      "6 (64, 28, 28, 1) (64,)\n"
     ]
    }
   ],
   "source": [
    "# We can iterate through a dataset like this:\n",
    "for t, (x, y) in enumerate(train_dset):\n",
    "    print(t, x.shape, y.shape)\n",
    "    if t > 5: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7bBfBfYpmde1"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3Pofr7mmde1"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1UqJbbQsmde1"
   },
   "source": [
    "#  Keras Model Subclassing API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMW3obRHmde1"
   },
   "source": [
    "\n",
    "Для реализации собственной модели с помощью Keras Model Subclassing API необходимо выполнить следующие шаги:\n",
    "\n",
    "1) Определить новый класс, который является наследником tf.keras.Model.\n",
    "\n",
    "2) В методе __init__() определить все необходимые слои из модуля tf.keras.layer\n",
    "\n",
    "3) Реализовать прямой проход в методе call() на основе слоев, объявленных в __init__()\n",
    "\n",
    "Ниже приведен пример использования keras API для определения двухслойной полносвязной сети.\n",
    "\n",
    "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T10:32:03.469890Z",
     "start_time": "2024-03-21T10:32:03.440894Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-HXiyu_mmde1",
    "outputId": "f5d467d7-6c38-4a41-c8c3-23588653cc5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anakonda\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer VarianceScaling is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "class TwoLayerFC(tf.keras.Model):\n",
    "    def __init__(self, hidden_size, num_classes):\n",
    "        super(TwoLayerFC, self).__init__()\n",
    "        initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
    "        self.fc1 = tf.keras.layers.Dense(hidden_size, activation='relu',\n",
    "                                   kernel_initializer=initializer)\n",
    "        self.fc2 = tf.keras.layers.Dense(num_classes, activation='softmax',\n",
    "                                   kernel_initializer=initializer)\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def test_TwoLayerFC():\n",
    "    \"\"\" A small unit test to exercise the TwoLayerFC model above. \"\"\"\n",
    "    input_size, hidden_size, num_classes = 50, 42, 10\n",
    "    x = tf.zeros((64, input_size))\n",
    "    model = TwoLayerFC(hidden_size, num_classes)\n",
    "    # with tf.device(device):\n",
    "    scores = model(x)\n",
    "    print(scores.shape)\n",
    "\n",
    "test_TwoLayerFC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v76VwT_cmde2"
   },
   "source": [
    "Реализуйте трехслойную CNN для вашей задачи классификации.\n",
    "\n",
    "Архитектура сети:\n",
    "    \n",
    "1. Сверточный слой (5 x 5 kernels, zero-padding = 'same')\n",
    "2. Функция активации ReLU\n",
    "3. Сверточный слой (3 x 3 kernels, zero-padding = 'same')\n",
    "4. Функция активации ReLU\n",
    "5. Полносвязный слой\n",
    "6. Функция активации Softmax\n",
    "\n",
    "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Conv2D\n",
    "\n",
    "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T10:32:03.485889Z",
     "start_time": "2024-03-21T10:32:03.471890Z"
    },
    "id": "9V4lPunEmde2"
   },
   "outputs": [],
   "source": [
    "class ThreeLayerConvNet(tf.keras.Model):\n",
    "    def __init__(self, channel_1, channel_2, num_classes):\n",
    "        super(ThreeLayerConvNet, self).__init__()\n",
    "        ########################################################################\n",
    "        # Определение слоев для сверточной нейронной сети.\n",
    "        ########################################################################\n",
    "        self.conv1 = tf.keras.layers.Conv2D(channel_1, (5, 5), padding='same', activation='relu')\n",
    "        self.conv2 = tf.keras.layers.Conv2D(channel_2, (3, 3), padding='same', activation='relu')\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.fc = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        ########################################################################\n",
    "        # Прямой проход для сверточной нейронной сети.\n",
    "        ########################################################################\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T10:32:03.533896Z",
     "start_time": "2024-03-21T10:32:03.511895Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-R34I4KXmde2",
    "outputId": "f5eaa650-713d-4b68-801b-7164814bfd19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 10)\n"
     ]
    }
   ],
   "source": [
    "def test_ThreeLayerConvNet():\n",
    "    channel_1, channel_2, num_classes = 12, 8, 10\n",
    "    model = ThreeLayerConvNet(channel_1, channel_2, num_classes)\n",
    "    with tf.device(device):\n",
    "        x = tf.zeros((64, 3, 32, 32))\n",
    "        scores = model(x)\n",
    "        print(scores.shape)\n",
    "\n",
    "test_ThreeLayerConvNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BBh2BMKzmde2"
   },
   "source": [
    "Пример реализации процесса обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T10:32:03.581893Z",
     "start_time": "2024-03-21T10:32:03.562890Z"
    },
    "id": "OxOMn46Bmde3"
   },
   "outputs": [],
   "source": [
    "def train_part34(model_init_fn, optimizer_init_fn, num_epochs=1, is_training=False):\n",
    "    \"\"\"\n",
    "    Simple training loop for use with models defined using tf.keras. It trains\n",
    "    a model for one epoch on the CIFAR-10 training set and periodically checks\n",
    "    accuracy on the CIFAR-10 validation set.\n",
    "\n",
    "    Inputs:\n",
    "    - model_init_fn: A function that takes no parameters; when called it\n",
    "      constructs the model we want to train: model = model_init_fn()\n",
    "    - optimizer_init_fn: A function which takes no parameters; when called it\n",
    "      constructs the Optimizer object we will use to optimize the model:\n",
    "      optimizer = optimizer_init_fn()\n",
    "    - num_epochs: The number of epochs to train for\n",
    "\n",
    "    Returns: Nothing, but prints progress during trainingn\n",
    "    \"\"\"\n",
    "    with tf.device(device):\n",
    "\n",
    "        # Compute the loss like we did in Part II\n",
    "        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "        model = model_init_fn()\n",
    "        optimizer = optimizer_init_fn()\n",
    "\n",
    "        train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "        train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "        val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "        val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='val_accuracy')\n",
    "\n",
    "        t = 0\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            # Reset the metrics - https://www.tensorflow.org/alpha/guide/migration_guide#new-style_metrics\n",
    "            train_loss.reset_states()\n",
    "            train_accuracy.reset_states()\n",
    "\n",
    "            for x_np, y_np in train_dset:\n",
    "                with tf.GradientTape() as tape:\n",
    "\n",
    "                    # Use the model function to build the forward pass.\n",
    "                    scores = model(x_np, training=is_training)\n",
    "                    loss = loss_fn(y_np, scores)\n",
    "\n",
    "                    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "                    # Update the metrics\n",
    "                    train_loss.update_state(loss)\n",
    "                    train_accuracy.update_state(y_np, scores)\n",
    "\n",
    "                    if t % print_every == 0:\n",
    "                        val_loss.reset_states()\n",
    "                        val_accuracy.reset_states()\n",
    "                        for test_x, test_y in val_dset:\n",
    "                            # During validation at end of epoch, training set to False\n",
    "                            prediction = model(test_x, training=False)\n",
    "                            t_loss = loss_fn(test_y, prediction)\n",
    "\n",
    "                            val_loss.update_state(t_loss)\n",
    "                            val_accuracy.update_state(test_y, prediction)\n",
    "\n",
    "                        template = 'Iteration {}, Epoch {}, Loss: {}, Accuracy: {}, Val Loss: {}, Val Accuracy: {}'\n",
    "                        print (template.format(t, epoch+1,\n",
    "                                             train_loss.result(),\n",
    "                                             train_accuracy.result()*100,\n",
    "                                             val_loss.result(),\n",
    "                                             val_accuracy.result()*100))\n",
    "                    t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T10:32:34.721805Z",
     "start_time": "2024-03-21T10:32:03.751891Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AKjdcmMhmde3",
    "outputId": "02d779ae-ad02-4d32-ff19-efd42d344c3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 2.8840699195861816, Accuracy: 7.8125, Val Loss: 2.6917357444763184, Val Accuracy: 23.600000381469727\n",
      "Iteration 100, Epoch 1, Loss: 0.6280143857002258, Accuracy: 81.09529876708984, Val Loss: 0.5261278748512268, Val Accuracy: 82.5\n",
      "Iteration 200, Epoch 1, Loss: 0.5032378435134888, Accuracy: 85.29228210449219, Val Loss: 0.44090139865875244, Val Accuracy: 87.0\n",
      "Iteration 300, Epoch 1, Loss: 0.44750645756721497, Accuracy: 86.92379760742188, Val Loss: 0.4048703610897064, Val Accuracy: 87.0999984741211\n",
      "Iteration 400, Epoch 1, Loss: 0.4049050211906433, Accuracy: 88.16630554199219, Val Loss: 0.3590394854545593, Val Accuracy: 89.20000457763672\n",
      "Iteration 500, Epoch 1, Loss: 0.38328954577445984, Accuracy: 88.80052185058594, Val Loss: 0.3398454487323761, Val Accuracy: 90.20000457763672\n",
      "Iteration 600, Epoch 1, Loss: 0.3611729145050049, Accuracy: 89.41087341308594, Val Loss: 0.3246558904647827, Val Accuracy: 91.0\n",
      "Iteration 700, Epoch 1, Loss: 0.34433794021606445, Accuracy: 89.91619110107422, Val Loss: 0.30381548404693604, Val Accuracy: 90.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hidden_size, num_classes = 4000, 10\n",
    "learning_rate = 1e-2\n",
    "\n",
    "def model_init_fn():\n",
    "    return TwoLayerFC(hidden_size, num_classes)\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    return tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jjGVqPb_mde3"
   },
   "source": [
    "Обучите трехслойную CNN. В tf.keras.optimizers.SGD укажите Nesterov momentum = 0.9 .\n",
    "\n",
    "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/optimizers/SGD\n",
    "\n",
    "Значение accuracy на валидационной выборке после 1 эпохи обучения должно быть > 50% ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T10:33:26.734189Z",
     "start_time": "2024-03-21T10:32:34.723805Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q-64ZL0mmde3",
    "outputId": "e1e7b50f-9e9c-4340-91da-d0ade64b3b8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 2.366486072540283, Accuracy: 10.9375, Val Loss: 2.342829465866089, Val Accuracy: 10.800000190734863\n",
      "Iteration 100, Epoch 1, Loss: 0.6668420433998108, Accuracy: 80.75494384765625, Val Loss: 0.5221271514892578, Val Accuracy: 83.0\n",
      "Iteration 200, Epoch 1, Loss: 0.5170328617095947, Accuracy: 85.07463073730469, Val Loss: 0.42704176902770996, Val Accuracy: 86.69999694824219\n",
      "Iteration 300, Epoch 1, Loss: 0.4358997046947479, Accuracy: 87.41175842285156, Val Loss: 0.2882182002067566, Val Accuracy: 91.9000015258789\n",
      "Iteration 400, Epoch 1, Loss: 0.37366825342178345, Accuracy: 89.14043426513672, Val Loss: 0.2394806444644928, Val Accuracy: 92.79999542236328\n",
      "Iteration 500, Epoch 1, Loss: 0.3341791331768036, Accuracy: 90.3193588256836, Val Loss: 0.20790891349315643, Val Accuracy: 93.80000305175781\n",
      "Iteration 600, Epoch 1, Loss: 0.3006870150566101, Accuracy: 91.2983627319336, Val Loss: 0.20222634077072144, Val Accuracy: 93.9000015258789\n",
      "Iteration 700, Epoch 1, Loss: 0.27511128783226013, Accuracy: 92.01809692382812, Val Loss: 0.1673082560300827, Val Accuracy: 94.30000305175781\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 3e-3\n",
    "channel_1, channel_2, num_classes = 32, 16, 10\n",
    "\n",
    "def model_init_fn():\n",
    "    model = None\n",
    "    ############################################################################\n",
    "    # TODO: Complete the implementation of model_fn.                           #\n",
    "    ############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    model = ThreeLayerConvNet(channel_1, channel_2, num_classes)\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ############################################################################\n",
    "    #                           END OF YOUR CODE                               #\n",
    "    ############################################################################\n",
    "    return model\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    optimizer = None\n",
    "    ############################################################################\n",
    "    # TODO: Complete the implementation of model_fn.                           #\n",
    "    ############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True)\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ############################################################################\n",
    "    #                           END OF YOUR CODE                               #\n",
    "    ############################################################################\n",
    "    return optimizer\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KPvuYgDWmde4"
   },
   "source": [
    "# Использование Keras Sequential API для реализации последовательных моделей.\n",
    "\n",
    "Пример для полносвязной сети:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T10:33:55.035281Z",
     "start_time": "2024-03-21T10:33:26.735190Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qjmdhDmSmde4",
    "outputId": "3e787cd1-d8c9-43be-ff8f-bd4378ff85e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 3.063081741333008, Accuracy: 14.0625, Val Loss: 2.650625467300415, Val Accuracy: 15.700000762939453\n",
      "Iteration 100, Epoch 1, Loss: 0.6567699909210205, Accuracy: 79.99691009521484, Val Loss: 0.5153436660766602, Val Accuracy: 84.5999984741211\n",
      "Iteration 200, Epoch 1, Loss: 0.5146311521530151, Accuracy: 84.6393051147461, Val Loss: 0.4504556357860565, Val Accuracy: 86.5\n",
      "Iteration 300, Epoch 1, Loss: 0.4549024701118469, Accuracy: 86.48255920410156, Val Loss: 0.4057101309299469, Val Accuracy: 87.4000015258789\n",
      "Iteration 400, Epoch 1, Loss: 0.4098382890224457, Accuracy: 87.87796020507812, Val Loss: 0.3639447093009949, Val Accuracy: 89.4000015258789\n",
      "Iteration 500, Epoch 1, Loss: 0.3868507146835327, Accuracy: 88.59468841552734, Val Loss: 0.35020047426223755, Val Accuracy: 90.4000015258789\n",
      "Iteration 600, Epoch 1, Loss: 0.3636132478713989, Accuracy: 89.27828979492188, Val Loss: 0.3281978368759155, Val Accuracy: 90.9000015258789\n",
      "Iteration 700, Epoch 1, Loss: 0.3457907736301422, Accuracy: 89.82257080078125, Val Loss: 0.3086647093296051, Val Accuracy: 90.4000015258789\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2\n",
    "\n",
    "def model_init_fn():\n",
    "    input_shape = (28,28,1)\n",
    "    hidden_layer_size, num_classes = 4000, 10\n",
    "    initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
    "    layers = [\n",
    "        tf.keras.layers.Flatten(input_shape=input_shape),\n",
    "        tf.keras.layers.Dense(hidden_layer_size, activation='relu',\n",
    "                              kernel_initializer=initializer),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax',\n",
    "                              kernel_initializer=initializer),\n",
    "    ]\n",
    "    model = tf.keras.Sequential(layers)\n",
    "    return model\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    return tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nvijUA_9mde4"
   },
   "source": [
    "Альтернативный менее гибкий способ обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T10:33:59.392586Z",
     "start_time": "2024-03-21T10:33:55.037282Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JJzOLRM2mde4",
    "outputId": "4f02a80c-b579-48ef-ff49-820d35067526"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "766/766 [==============================] - 7s 8ms/step - loss: 0.3429 - sparse_categorical_accuracy: 0.8989 - val_loss: 0.3174 - val_sparse_categorical_accuracy: 0.9030\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2238 - sparse_categorical_accuracy: 0.9355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.22382304072380066, 0.9355000257492065]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_init_fn()\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=1, validation_data=(X_val, y_val))\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UtXOP9immde4"
   },
   "source": [
    "Перепишите реализацию трехслойной CNN с помощью tf.keras.Sequential API . Обучите модель двумя способами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T10:34:49.743065Z",
     "start_time": "2024-03-21T10:33:59.393586Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xv4nD7N3mde5",
    "outputId": "4e0ddd89-08b3-4abb-f062-d1a26ed46df1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 2.2997660636901855, Accuracy: 9.375, Val Loss: 2.3207502365112305, Val Accuracy: 6.400000095367432\n",
      "Iteration 100, Epoch 1, Loss: 2.290864944458008, Accuracy: 10.983911514282227, Val Loss: 2.2642266750335693, Val Accuracy: 16.200000762939453\n",
      "Iteration 200, Epoch 1, Loss: 2.25793194770813, Accuracy: 18.275808334350586, Val Loss: 2.2039475440979004, Val Accuracy: 31.5\n",
      "Iteration 300, Epoch 1, Loss: 2.224306344985962, Accuracy: 25.680023193359375, Val Loss: 2.1272246837615967, Val Accuracy: 45.89999771118164\n",
      "Iteration 400, Epoch 1, Loss: 2.1791484355926514, Accuracy: 33.38138961791992, Val Loss: 2.0072836875915527, Val Accuracy: 58.0\n",
      "Iteration 500, Epoch 1, Loss: 2.122676134109497, Accuracy: 39.670658111572266, Val Loss: 1.8313952684402466, Val Accuracy: 64.30000305175781\n",
      "Iteration 600, Epoch 1, Loss: 2.0446672439575195, Accuracy: 44.922523498535156, Val Loss: 1.577453374862671, Val Accuracy: 68.80000305175781\n",
      "Iteration 700, Epoch 1, Loss: 1.9474666118621826, Accuracy: 49.17528533935547, Val Loss: 1.2833912372589111, Val Accuracy: 72.5999984741211\n"
     ]
    }
   ],
   "source": [
    "def model_init_fn():\n",
    "    model = None\n",
    "    ############################################################################\n",
    "    # TODO: Construct a three-layer ConvNet using tf.keras.Sequential.         #\n",
    "    ############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    model = ThreeLayerConvNet(channel_1, channel_2, num_classes)\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ############################################################################\n",
    "    #                            END OF YOUR CODE                              #\n",
    "    ############################################################################\n",
    "    return model\n",
    "\n",
    "learning_rate = 5e-4\n",
    "def optimizer_init_fn():\n",
    "    optimizer = None\n",
    "    ############################################################################\n",
    "    # TODO: Complete the implementation of model_fn.                           #\n",
    "    ############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ############################################################################\n",
    "    #                           END OF YOUR CODE                               #\n",
    "    ############################################################################\n",
    "    return optimizer\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-21T10:34:49.744065Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FIRJ96Exmde5",
    "is_executing": true,
    "outputId": "91652cea-40aa-4412-fd86-abdb37c41952"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "766/766 [==============================] - 11s 13ms/step - loss: 0.3843 - sparse_categorical_accuracy: 0.8872 - val_loss: 0.2610 - val_sparse_categorical_accuracy: 0.9300\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.1717 - sparse_categorical_accuracy: 0.9471\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.17168748378753662, 0.9470999836921692]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_init_fn()\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=1, validation_data=(X_val, y_val))\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rMHQrrbzmde5"
   },
   "source": [
    "# Использование Keras Functional API\n",
    "\n",
    "Для реализации более сложных архитектур сети с несколькими входами/выходами, повторным использованием слоев, \"остаточными\" связями (residual connections) необходимо явно указать входные и выходные тензоры.\n",
    "\n",
    "Ниже представлен пример для полносвязной сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CdKAP4Gjmde5",
    "outputId": "f6ec5eb0-218e-42ae-e523-4b55dd22b0f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 10)\n"
     ]
    }
   ],
   "source": [
    "def two_layer_fc_functional(input_shape, hidden_size, num_classes):\n",
    "    initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    flattened_inputs = tf.keras.layers.Flatten()(inputs)\n",
    "    fc1_output = tf.keras.layers.Dense(hidden_size, activation='relu',\n",
    "                                 kernel_initializer=initializer)(flattened_inputs)\n",
    "    scores = tf.keras.layers.Dense(num_classes, activation='softmax',\n",
    "                             kernel_initializer=initializer)(fc1_output)\n",
    "\n",
    "    # Instantiate the model given inputs and outputs.\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=scores)\n",
    "    return model\n",
    "\n",
    "def test_two_layer_fc_functional():\n",
    "    \"\"\" A small unit test to exercise the TwoLayerFC model above. \"\"\"\n",
    "    input_size, hidden_size, num_classes = 50, 42, 10\n",
    "    input_shape = (50,)\n",
    "\n",
    "    x = tf.zeros((64, input_size))\n",
    "    model = two_layer_fc_functional(input_shape, hidden_size, num_classes)\n",
    "\n",
    "    with tf.device(device):\n",
    "        scores = model(x)\n",
    "        print(scores.shape)\n",
    "\n",
    "test_two_layer_fc_functional()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wCnxBWsxmde5",
    "outputId": "36a11af2-e38d-4ca3-9e32-0e837a891c07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 3.1502909660339355, Accuracy: 6.25, Val Loss: 2.625807762145996, Val Accuracy: 15.80000114440918\n",
      "Iteration 100, Epoch 1, Loss: 0.6259249448776245, Accuracy: 80.92512512207031, Val Loss: 0.5451792478561401, Val Accuracy: 82.5\n",
      "Iteration 200, Epoch 1, Loss: 0.49515366554260254, Accuracy: 85.28451538085938, Val Loss: 0.44531258940696716, Val Accuracy: 87.19999694824219\n",
      "Iteration 300, Epoch 1, Loss: 0.4393361806869507, Accuracy: 86.99647521972656, Val Loss: 0.40034258365631104, Val Accuracy: 87.30000305175781\n",
      "Iteration 400, Epoch 1, Loss: 0.39786389470100403, Accuracy: 88.25592041015625, Val Loss: 0.3628551959991455, Val Accuracy: 89.30000305175781\n",
      "Iteration 500, Epoch 1, Loss: 0.37650197744369507, Accuracy: 88.9252700805664, Val Loss: 0.3489495515823364, Val Accuracy: 90.5999984741211\n",
      "Iteration 600, Epoch 1, Loss: 0.35414251685142517, Accuracy: 89.5668716430664, Val Loss: 0.33209818601608276, Val Accuracy: 90.9000015258789\n",
      "Iteration 700, Epoch 1, Loss: 0.33743706345558167, Accuracy: 90.07890319824219, Val Loss: 0.3113998770713806, Val Accuracy: 91.0\n"
     ]
    }
   ],
   "source": [
    "input_shape = (28, 28, 1)\n",
    "hidden_size, num_classes = 4000, 10\n",
    "learning_rate = 1e-2\n",
    "\n",
    "def model_init_fn():\n",
    "    return two_layer_fc_functional(input_shape, hidden_size, num_classes)\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    return tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejJunY24mde6"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F9Gcduahmde6"
   },
   "source": [
    "Поэкспериментируйте с архитектурой сверточной сети. Для вашего набора данных вам необходимо получить как минимум 70% accuracy на валидационной выборке за 10 эпох обучения. Опишите все эксперименты и сделайте выводы (без выполнения данного пункта работы приниматься не будут).\n",
    "\n",
    "Эспериментируйте с архитектурой, гиперпараметрами, функцией потерь, регуляризацией, методом оптимизации.  \n",
    "\n",
    "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/BatchNormalization#methods https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Dropout#methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "dyKT825Imde6"
   },
   "outputs": [],
   "source": [
    "class _IdentityBlock(tf.keras.Model):\n",
    "    \"\"\"Identity block utilizing skip connections.\"\"\"\n",
    "\n",
    "    def __init__(self, out_channels):\n",
    "        super().__init__()\n",
    "        \"\"\"Initializes the identiy block.\n",
    "\n",
    "        Here we simply initialize 2 layers which process the input and after the output\n",
    "        is produces it is added together with the input whcih is the final output.\n",
    "\n",
    "        Args:\n",
    "            out_channels (int): The number of activation maps this block should produce\n",
    "        \"\"\"\n",
    "        # Acts as Kaiming weight initalization\n",
    "        initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
    "\n",
    "        # Part 1 of the convolution, normalization and non-linearity\n",
    "        self.conv1 = tf.keras.layers.Conv2D(out_channels, 3, padding='same', use_bias=False, kernel_initializer=initializer)\n",
    "        self.norm1 = tf.keras.layers.BatchNormalization(axis=3)\n",
    "        self.relu1 = tf.keras.layers.Activation('relu')\n",
    "\n",
    "        # Part 2 of the convolution, normalization and non-linearity\n",
    "        self.conv2 = tf.keras.layers.Conv2D(out_channels, 3, padding='same', use_bias=False, kernel_initializer=initializer)\n",
    "        self.norm2 = tf.keras.layers.BatchNormalization(axis=3)\n",
    "        self.relu2 = tf.keras.layers.Activation('relu')\n",
    "\n",
    "        # Add layer will add together the input and the output\n",
    "        self.add = tf.keras.layers.Add()\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        \"\"\"Performs forward pass on the given input.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor):      The input of dimensions (N, H, W, C)\n",
    "            training (bool): Indicates whether the forward pass happens in the training mode\n",
    "\n",
    "        Returns:\n",
    "              out (Tensor): Output data of dim (N, H, W, C)\n",
    "        \"\"\"\n",
    "        x_skip = tf.identity(x)                   # prepare to add the input to the output\n",
    "        x = self.relu1(self.norm1(self.conv1(x))) # pass input through the first layer\n",
    "        x = self.norm2(self.conv2(x))             # pass input through the second layer (without ReLU)\n",
    "        out = self.relu2(self.add([x, x_skip]))   # perform ReLU on the processed input added with the raw input\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, in_channels=32, block_config=(2, 2, 2, 2), num_classes=10):\n",
    "        \"\"\"Initializes the residual network.\n",
    "\n",
    "        The first layer produces `in_channels` activation maps which are then fed to a\n",
    "        sequence of blocks containing a specified number of identity sub-blocks (first\n",
    "        block is always *_BottleneckBlock*). At the end the _global average pooling_\n",
    "        layer is used to flatten the activations for the linear softmax classifier.\n",
    "\n",
    "        Args:\n",
    "            in_channels (int):    The number of channels to extract after the first convolution\n",
    "            block_config (tuple): The number of layers each bloack should have in sequence\n",
    "            num_classes (int):    The total number of classes\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Acts as Kaiming weight initalization\n",
    "        initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
    "\n",
    "        # Prepare the input for the chains of identity blocks\n",
    "        self.features = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(in_channels, 5, padding='same', use_bias=False, kernel_initializer=initializer),\n",
    "            tf.keras.layers.BatchNormalization(axis=3),\n",
    "            tf.keras.layers.Activation('relu'),\n",
    "        ])\n",
    "\n",
    "        num_features = in_channels # num feaure maps to produce after each group of identity blocks\n",
    "\n",
    "        # Loop through every group of blocks\n",
    "        for i, num_layers in enumerate(block_config):\n",
    "            # Use bottleneck block as the first block in every group (except first)\n",
    "            if i != 0:\n",
    "                self.features.add(_BottleneckBlock(num_features))\n",
    "            else:\n",
    "                self.features.add(_IdentityBlock(num_features))\n",
    "\n",
    "            # Create the specified number of identity blocks for i'th group\n",
    "            for j in range(num_layers-1):\n",
    "                self.features.add(_IdentityBlock(num_features))\n",
    "\n",
    "            num_features *= 2 # increase the nuber of features to be produced\n",
    "\n",
    "        # Flatten the final activation maps using global average pooling\n",
    "        self.features.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "\n",
    "        # Softmax classifier is used as the final layer\n",
    "        self.classifier = tf.keras.layers.Dense(num_classes, activation='softmax', kernel_initializer=initializer)\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        \"\"\"Performs forward pass on the given input.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor):      The input of dimensions (N, H, W, C)\n",
    "            training (bool): Indicates whether the forward pass happens in the training mode\n",
    "\n",
    "        Returns:\n",
    "            out (Tensor): Output data of dim (N, 10)\n",
    "        \"\"\"\n",
    "        out = self.features(x)     # Get the extracted features for the linear classfier\n",
    "        out = self.classifier(out) # Perform classification with softmax activation\n",
    "\n",
    "        return out\n",
    "class _BottleneckBlock(tf.keras.Model):\n",
    "    \"\"\"Same as identity block except it reduces the spacial area before processing the input.\"\"\"\n",
    "\n",
    "    def __init__(self, out_channels):\n",
    "        \"\"\"Initializes the bottleneck block.\n",
    "\n",
    "        Unlike *_IdentityBlock*, the first convolution here reduces the spacial size of the input\n",
    "        by a factor of `2`. Then, it performs the main convolution after which the output maps\n",
    "        are added together with the input maps to produce final activations.\n",
    "\n",
    "        Args:\n",
    "            out_channels (int): The number of activation maps this block should produce\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Acts as Kaiming weight initalization\n",
    "        initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
    "\n",
    "        # Reduce the input size by 2 to match output size\n",
    "        self.skip1 = tf.keras.layers.Conv2D(out_channels, 1, strides=2, use_bias=False, kernel_initializer=initializer)\n",
    "\n",
    "        # Part 1 of the convolution which reduces the spacial area\n",
    "        self.conv1 = tf.keras.layers.Conv2D(out_channels, 3, strides=2, padding='same', use_bias=False, kernel_initializer=initializer)\n",
    "        self.norm1 = tf.keras.layers.BatchNormalization(axis=3)\n",
    "        self.relu1 = tf.keras.layers.Activation('relu')\n",
    "\n",
    "        # Part 2 of the convolution which extracts features from the reduced input\n",
    "        self.conv2 = tf.keras.layers.Conv2D(out_channels, 3, padding='same', use_bias=False, kernel_initializer=initializer)\n",
    "        self.norm2 = tf.keras.layers.BatchNormalization(axis=3)\n",
    "        self.relu2 = tf.keras.layers.Activation('relu')\n",
    "\n",
    "        # Add layer will add together the input and the output\n",
    "        self.add = tf.keras.layers.Add()\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        \"\"\"Performs forward pass on the given input.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor):      The input of dimensions (N, H, W, C)\n",
    "            training (bool): Indicates whether the forward pass happens in the training mode\n",
    "\n",
    "        Returns:\n",
    "            out (Tensor): Output data of dim (N, H/2, W/2, out_channels)\n",
    "        \"\"\"\n",
    "        x_skip = self.skip1(x)                    # prepare to add the input to the output\n",
    "        x = self.relu1(self.norm1(self.conv1(x))) # pass input through the first layer\n",
    "        x = self.norm2(self.conv2(x))             # pass input through the second layer (without ReLU)\n",
    "        out = self.relu2(self.add([x, x_skip]))   # perform ReLU on the processed input added with the raw input\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W4l_Ityxmde6",
    "outputId": "1749d277-95cf-4ad9-b8ca-7a7b95e4a9f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 4.009794235229492, Accuracy: 6.25, Val Loss: 127.6778793334961, Val Accuracy: 10.699999809265137\n",
      "Iteration 100, Epoch 1, Loss: 0.40878623723983765, Accuracy: 87.94863891601562, Val Loss: 5.104014873504639, Val Accuracy: 35.900001525878906\n",
      "Iteration 200, Epoch 1, Loss: 0.2821394205093384, Accuracy: 91.66667175292969, Val Loss: 0.40873831510543823, Val Accuracy: 88.80000305175781\n",
      "Iteration 300, Epoch 1, Loss: 0.22032441198825836, Accuracy: 93.48007202148438, Val Loss: 0.44638580083847046, Val Accuracy: 89.0\n",
      "Iteration 400, Epoch 1, Loss: 0.182871475815773, Accuracy: 94.57605743408203, Val Loss: 0.4412424862384796, Val Accuracy: 88.30000305175781\n",
      "Iteration 500, Epoch 1, Loss: 0.16443847119808197, Accuracy: 95.1316146850586, Val Loss: 0.22244659066200256, Val Accuracy: 93.0999984741211\n",
      "Iteration 600, Epoch 1, Loss: 0.15051861107349396, Accuracy: 95.556884765625, Val Loss: 0.27871453762054443, Val Accuracy: 92.19999694824219\n",
      "Iteration 700, Epoch 1, Loss: 0.13938073813915253, Accuracy: 95.89425659179688, Val Loss: 0.14884695410728455, Val Accuracy: 95.4000015258789\n",
      "Iteration 800, Epoch 2, Loss: 0.06200695037841797, Accuracy: 98.2589340209961, Val Loss: 0.10140671581029892, Val Accuracy: 97.0\n",
      "Iteration 900, Epoch 2, Loss: 0.056292615830898285, Accuracy: 98.28704071044922, Val Loss: 0.08736631274223328, Val Accuracy: 97.29999542236328\n",
      "Iteration 1000, Epoch 2, Loss: 0.052474211901426315, Accuracy: 98.37100982666016, Val Loss: 0.10830391198396683, Val Accuracy: 97.0999984741211\n",
      "Iteration 1100, Epoch 2, Loss: 0.04771941900253296, Accuracy: 98.5307846069336, Val Loss: 0.09949230402708054, Val Accuracy: 96.4000015258789\n",
      "Iteration 1200, Epoch 2, Loss: 0.04607006907463074, Accuracy: 98.5811767578125, Val Loss: 0.11798354238271713, Val Accuracy: 97.0\n",
      "Iteration 1300, Epoch 2, Loss: 0.04431113228201866, Accuracy: 98.66238403320312, Val Loss: 0.10027610510587692, Val Accuracy: 97.5999984741211\n",
      "Iteration 1400, Epoch 2, Loss: 0.04482279345393181, Accuracy: 98.65157318115234, Val Loss: 0.11541472375392914, Val Accuracy: 96.5\n",
      "Iteration 1500, Epoch 2, Loss: 0.04362767934799194, Accuracy: 98.69473266601562, Val Loss: 0.11241239309310913, Val Accuracy: 97.0\n",
      "Iteration 1600, Epoch 3, Loss: 0.03403518721461296, Accuracy: 99.09420013427734, Val Loss: 0.07399013638496399, Val Accuracy: 97.5999984741211\n",
      "Iteration 1700, Epoch 3, Loss: 0.0332099013030529, Accuracy: 99.0477066040039, Val Loss: 0.4278903007507324, Val Accuracy: 87.4000015258789\n",
      "Iteration 1800, Epoch 3, Loss: 0.030109716579318047, Accuracy: 99.14033508300781, Val Loss: 0.12753227353096008, Val Accuracy: 96.10000610351562\n",
      "Iteration 1900, Epoch 3, Loss: 0.026948342099785805, Accuracy: 99.23356628417969, Val Loss: 0.08022614568471909, Val Accuracy: 97.39999389648438\n",
      "Iteration 2000, Epoch 3, Loss: 0.027078963816165924, Accuracy: 99.21708679199219, Val Loss: 0.1264650821685791, Val Accuracy: 97.0999984741211\n",
      "Iteration 2100, Epoch 3, Loss: 0.026733962818980217, Accuracy: 99.21463012695312, Val Loss: 0.10624149441719055, Val Accuracy: 96.5\n",
      "Iteration 2200, Epoch 3, Loss: 0.02797546423971653, Accuracy: 99.1545181274414, Val Loss: 0.12032500654459, Val Accuracy: 97.19999694824219\n",
      "Iteration 2300, Epoch 4, Loss: 0.045224834233522415, Accuracy: 98.4375, Val Loss: 0.08607736229896545, Val Accuracy: 97.69999694824219\n",
      "Iteration 2400, Epoch 4, Loss: 0.029773563146591187, Accuracy: 99.08980560302734, Val Loss: 0.16327892243862152, Val Accuracy: 95.5999984741211\n",
      "Iteration 2500, Epoch 4, Loss: 0.03120795637369156, Accuracy: 99.04557037353516, Val Loss: 0.1870012730360031, Val Accuracy: 95.70000457763672\n",
      "Iteration 2600, Epoch 4, Loss: 0.027463607490062714, Accuracy: 99.12335205078125, Val Loss: 0.06597141921520233, Val Accuracy: 98.19999694824219\n",
      "Iteration 2700, Epoch 4, Loss: 0.02511647157371044, Accuracy: 99.21681213378906, Val Loss: 0.07189667224884033, Val Accuracy: 97.69999694824219\n",
      "Iteration 2800, Epoch 4, Loss: 0.025178760290145874, Accuracy: 99.2140884399414, Val Loss: 0.08208565413951874, Val Accuracy: 97.79999542236328\n",
      "Iteration 2900, Epoch 4, Loss: 0.024984221905469894, Accuracy: 99.21745300292969, Val Loss: 0.18433187901973724, Val Accuracy: 95.20000457763672\n",
      "Iteration 3000, Epoch 4, Loss: 0.024998074397444725, Accuracy: 99.21764373779297, Val Loss: 0.16665540635585785, Val Accuracy: 96.20000457763672\n",
      "Iteration 3100, Epoch 5, Loss: 0.026329338550567627, Accuracy: 99.0709457397461, Val Loss: 0.10376660525798798, Val Accuracy: 97.29999542236328\n",
      "Iteration 3200, Epoch 5, Loss: 0.023884326219558716, Accuracy: 99.24726867675781, Val Loss: 0.09318690747022629, Val Accuracy: 97.0999984741211\n",
      "Iteration 3300, Epoch 5, Loss: 0.020954949781298637, Accuracy: 99.3473129272461, Val Loss: 0.10382987558841705, Val Accuracy: 97.39999389648438\n",
      "Iteration 3400, Epoch 5, Loss: 0.019024334847927094, Accuracy: 99.41580200195312, Val Loss: 0.0744873434305191, Val Accuracy: 97.89999389648438\n",
      "Iteration 3500, Epoch 5, Loss: 0.01854492351412773, Accuracy: 99.41719055175781, Val Loss: 0.09715334326028824, Val Accuracy: 97.69999694824219\n",
      "Iteration 3600, Epoch 5, Loss: 0.019006704911589622, Accuracy: 99.40060424804688, Val Loss: 0.1173686683177948, Val Accuracy: 96.5999984741211\n",
      "Iteration 3700, Epoch 5, Loss: 0.019123874604701996, Accuracy: 99.39903259277344, Val Loss: 0.09532732516527176, Val Accuracy: 97.5\n",
      "Iteration 3800, Epoch 5, Loss: 0.018862711265683174, Accuracy: 99.4127426147461, Val Loss: 0.10897622257471085, Val Accuracy: 97.39999389648438\n",
      "Iteration 3900, Epoch 6, Loss: 0.026150573045015335, Accuracy: 98.9876708984375, Val Loss: 0.1079423651099205, Val Accuracy: 97.0\n",
      "Iteration 4000, Epoch 6, Loss: 0.020057521760463715, Accuracy: 99.33296966552734, Val Loss: 0.15252313017845154, Val Accuracy: 95.0999984741211\n",
      "Iteration 4100, Epoch 6, Loss: 0.018413947895169258, Accuracy: 99.38883972167969, Val Loss: 0.06740294396877289, Val Accuracy: 98.5\n",
      "Iteration 4200, Epoch 6, Loss: 0.017134567722678185, Accuracy: 99.4103775024414, Val Loss: 0.08727451413869858, Val Accuracy: 97.5999984741211\n",
      "Iteration 4300, Epoch 6, Loss: 0.017176060006022453, Accuracy: 99.41944885253906, Val Loss: 0.07419931888580322, Val Accuracy: 98.0999984741211\n",
      "Iteration 4400, Epoch 6, Loss: 0.01642957143485546, Accuracy: 99.44450378417969, Val Loss: 0.09296295791864395, Val Accuracy: 98.0\n",
      "Iteration 4500, Epoch 6, Loss: 0.016604803502559662, Accuracy: 99.4434585571289, Val Loss: 0.10392260551452637, Val Accuracy: 97.0999984741211\n",
      "Iteration 4600, Epoch 7, Loss: 0.023374876007437706, Accuracy: 99.0625, Val Loss: 0.07276809215545654, Val Accuracy: 98.0999984741211\n",
      "Iteration 4700, Epoch 7, Loss: 0.014087753370404243, Accuracy: 99.53868865966797, Val Loss: 0.08183324337005615, Val Accuracy: 97.69999694824219\n",
      "Iteration 4800, Epoch 7, Loss: 0.013320649974048138, Accuracy: 99.54268646240234, Val Loss: 0.1761000156402588, Val Accuracy: 96.0\n",
      "Iteration 4900, Epoch 7, Loss: 0.013559495098888874, Accuracy: 99.56454467773438, Val Loss: 0.07751934975385666, Val Accuracy: 98.0\n",
      "Iteration 5000, Epoch 7, Loss: 0.014705034904181957, Accuracy: 99.5293197631836, Val Loss: 0.10018274933099747, Val Accuracy: 97.29999542236328\n",
      "Iteration 5100, Epoch 7, Loss: 0.014622841961681843, Accuracy: 99.51732635498047, Val Loss: 0.11707349121570587, Val Accuracy: 97.79999542236328\n",
      "Iteration 5200, Epoch 7, Loss: 0.014604500494897366, Accuracy: 99.52220916748047, Val Loss: 0.10575736314058304, Val Accuracy: 97.5999984741211\n",
      "Iteration 5300, Epoch 7, Loss: 0.014889607205986977, Accuracy: 99.52571105957031, Val Loss: 0.12254388630390167, Val Accuracy: 96.0\n",
      "Iteration 5400, Epoch 8, Loss: 0.03253078833222389, Accuracy: 98.99839782714844, Val Loss: 0.10891864448785782, Val Accuracy: 96.9000015258789\n",
      "Iteration 5500, Epoch 8, Loss: 0.020151888951659203, Accuracy: 99.3255386352539, Val Loss: 0.048082903027534485, Val Accuracy: 98.29999542236328\n",
      "Iteration 5600, Epoch 8, Loss: 0.0160262081772089, Accuracy: 99.45083618164062, Val Loss: 0.04807674512267113, Val Accuracy: 98.69999694824219\n",
      "Iteration 5700, Epoch 8, Loss: 0.0135413259267807, Accuracy: 99.55290985107422, Val Loss: 0.046410366892814636, Val Accuracy: 98.4000015258789\n",
      "Iteration 5800, Epoch 8, Loss: 0.012564494274556637, Accuracy: 99.58357238769531, Val Loss: 0.08270645141601562, Val Accuracy: 98.19999694824219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5900, Epoch 8, Loss: 0.01157704833894968, Accuracy: 99.60865020751953, Val Loss: 0.05232682451605797, Val Accuracy: 98.5999984741211\n",
      "Iteration 6000, Epoch 8, Loss: 0.012547721154987812, Accuracy: 99.57942199707031, Val Loss: 0.11447490751743317, Val Accuracy: 97.5\n",
      "Iteration 6100, Epoch 8, Loss: 0.013234215788543224, Accuracy: 99.5517578125, Val Loss: 0.11929888278245926, Val Accuracy: 97.5\n",
      "Iteration 6200, Epoch 9, Loss: 0.01165104005485773, Accuracy: 99.5719223022461, Val Loss: 0.05349003151059151, Val Accuracy: 98.4000015258789\n",
      "Iteration 6300, Epoch 9, Loss: 0.010218532755970955, Accuracy: 99.66582489013672, Val Loss: 0.05926158279180527, Val Accuracy: 98.4000015258789\n",
      "Iteration 6400, Epoch 9, Loss: 0.009462381713092327, Accuracy: 99.70238494873047, Val Loss: 0.0628432184457779, Val Accuracy: 98.0999984741211\n",
      "Iteration 6500, Epoch 9, Loss: 0.009630504995584488, Accuracy: 99.71932983398438, Val Loss: 0.05669794976711273, Val Accuracy: 98.9000015258789\n",
      "Iteration 6600, Epoch 9, Loss: 0.009299452416598797, Accuracy: 99.72911834716797, Val Loss: 0.07732774317264557, Val Accuracy: 98.4000015258789\n",
      "Iteration 6700, Epoch 9, Loss: 0.00898242462426424, Accuracy: 99.7327651977539, Val Loss: 0.09179848432540894, Val Accuracy: 97.79999542236328\n",
      "Iteration 6800, Epoch 9, Loss: 0.008874989114701748, Accuracy: 99.73068237304688, Val Loss: 0.0909220427274704, Val Accuracy: 97.5\n",
      "Iteration 6900, Epoch 10, Loss: 0.009546617045998573, Accuracy: 99.77678680419922, Val Loss: 0.0665479302406311, Val Accuracy: 98.4000015258789\n",
      "Iteration 7000, Epoch 10, Loss: 0.012350659817457199, Accuracy: 99.57652282714844, Val Loss: 0.23172849416732788, Val Accuracy: 95.20000457763672\n",
      "Iteration 7100, Epoch 10, Loss: 0.018955552950501442, Accuracy: 99.35839080810547, Val Loss: 0.18277938663959503, Val Accuracy: 96.30000305175781\n",
      "Iteration 7200, Epoch 10, Loss: 0.017665941268205643, Accuracy: 99.42996215820312, Val Loss: 0.06027694046497345, Val Accuracy: 98.9000015258789\n",
      "Iteration 7300, Epoch 10, Loss: 0.015612988732755184, Accuracy: 99.4894027709961, Val Loss: 0.048118919134140015, Val Accuracy: 98.5\n",
      "Iteration 7400, Epoch 10, Loss: 0.014449793845415115, Accuracy: 99.52847290039062, Val Loss: 0.0978228822350502, Val Accuracy: 97.79999542236328\n",
      "Iteration 7500, Epoch 10, Loss: 0.013702037744224072, Accuracy: 99.54437255859375, Val Loss: 0.05643216893076897, Val Accuracy: 98.5\n",
      "Iteration 7600, Epoch 10, Loss: 0.01322171650826931, Accuracy: 99.55357360839844, Val Loss: 0.12384261190891266, Val Accuracy: 97.19999694824219\n"
     ]
    }
   ],
   "source": [
    "class CustomConvNet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(CustomConvNet, self).__init__()\n",
    "        ############################################################################\n",
    "        # TODO: Construct a model that performs well on CIFAR-10                   #\n",
    "        ############################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "        self.model = ResNet()\n",
    "\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ############################################################################\n",
    "        #                            END OF YOUR CODE                              #\n",
    "        ############################################################################\n",
    "\n",
    "    def call(self, input_tensor, training=False):\n",
    "        ############################################################################\n",
    "        # TODO: Construct a model that performs well on CIFAR-10                   #\n",
    "        ############################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "        x = self.model.call(input_tensor, training)\n",
    "\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ############################################################################\n",
    "        #                            END OF YOUR CODE                              #\n",
    "        ############################################################################\n",
    "        return x\n",
    "\n",
    "\n",
    "print_every = 100\n",
    "num_epochs = 10\n",
    "\n",
    "model = CustomConvNet()\n",
    "\n",
    "def model_init_fn():\n",
    "    return CustomConvNet()\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    learning_rate = 1e-3\n",
    "    return tf.keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn, num_epochs=num_epochs, is_training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nREnkxK3mde7"
   },
   "source": [
    "Опишите все эксперименты, результаты. Сделайте выводы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWa5BMuIroCi"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Y5OZJJumde7"
   },
   "source": [
    "  Была реализована следующая архитектура:\n",
    "        1. `CONV->NORM->RELU->CONV->NORM->RELU` для предварительной обработки входного сигнала для цепочки блоков слоев\n",
    "        2. `IDENTITY->[BOTTLENECK->IDENTITY] x N`, где каждый блок состоит из произвольного\n",
    "           где каждый блок состоит из произвольного количества слоев, использующих \"skip\" соединения\n",
    "        3. `POOL->DENSE->SOFTMAX`, где выполняется глобальное усреднение пула\n",
    "           перед вычислением raw scores\n",
    "В результате произведенной работы были получены необходимые результаты уже на 3 эпохе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
